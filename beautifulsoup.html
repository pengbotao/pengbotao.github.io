<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
    <title>Python爬虫库 ( 5 ) - BeautifulSoup</title>
    <link rel="stylesheet" href="/static/css/markdown.css">
    
</head>
<body>
<div class="content">
    <h1 class="title">Python爬虫库 ( 5 ) - BeautifulSoup</h1>

    <a href="/"><img src="/static/img/arrow-back.png" class="title_arrow_back" /></a>

    <p>Beautiful Soup 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup会帮你节省数小时甚至数天的工作时间.</p>

<h1 id="一-安装">一、安装</h1>

<pre><code>pip install bs4
</code></pre>

<h2 id="1-1-加载-从字符串加载">1.1 加载（从字符串加载）</h2>

<pre><code>html_doc = &quot;&quot;&quot;
&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta http-equiv=&quot;Content-type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;
    &lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src 'none'; style-src 'unsafe-inline'; img-src data:; connect-src 'self'&quot;&gt;
    &lt;title&gt;Page not found &amp;middot; GitHub Pages&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;

    &lt;div class=&quot;container&quot;&gt;

      &lt;h1&gt;404&lt;/h1&gt;
      &lt;p&gt;&lt;strong&gt;File not found&lt;/strong&gt;&lt;/p&gt;

      &lt;p&gt;
        The site configured at this address does not
        contain the requested file.
      &lt;/p&gt;

      &lt;p&gt;
        If this is your site, make sure that the filename case matches the URL.&lt;br&gt;
        For root URLs (like &lt;code&gt;http://example.com/&lt;/code&gt;) you must provide an
        &lt;code&gt;index.html&lt;/code&gt; file.
      &lt;/p&gt;

      &lt;p&gt;
        &lt;a href=&quot;https://help.github.com/pages/&quot;&gt;Read the full documentation&lt;/a&gt;
        for more information about using &lt;strong&gt;GitHub Pages&lt;/strong&gt;.
      &lt;/p&gt;

      &lt;div id=&quot;suggestions&quot;&gt;
        &lt;a href=&quot;https://githubstatus.com&quot;&gt;GitHub Status&lt;/a&gt; &amp;mdash;
        &lt;a href=&quot;https://twitter.com/githubstatus&quot;&gt;@githubstatus&lt;/a&gt;
      &lt;/div&gt;

      &lt;a href=&quot;/&quot; class=&quot;logo logo-img-1x&quot;&gt;
        &lt;img width=&quot;32&quot; height=&quot;32&quot; title=&quot;&quot; alt=&quot;&quot; src=&quot;http://1.png&quot;&gt;
      &lt;/a&gt;

      &lt;a href=&quot;/&quot; class=&quot;logo logo-img-2x&quot;&gt;
        &lt;img width=&quot;32&quot; height=&quot;32&quot; title=&quot;&quot; alt=&quot;&quot; src=&quot;http://2.png&quot;&gt;
      &lt;/a&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
&quot;&quot;&quot;
</code></pre>

<p>以上<code>Github Pages</code>的404页面，使用<code>BeautifulSou</code>p解析这段代码,能够得到一个<code>BeautifulSoup</code>的对象,并能按照标准的缩进格式的结构输出:</p>

<pre><code>from bs4 import BeautifulSoup

# Load Html字符串，并使用标准库来解析
soup = BeautifulSoup(html_doc, 'html.parser')

print(soup.prettify())
</code></pre>

<h2 id="1-2-加载-从文件加载">1.2 加载（从文件加载）</h2>

<pre><code>soup = BeautifulSoup(open(&quot;index.html&quot;))
</code></pre>

<h2 id="1-3-解析器列表">1.3 解析器列表</h2>

<table>
<thead>
<tr>
<th>解析器</th>
<th>使用方法</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>Python标准库（默认）</strong></td>
<td>BeautifulSoup(markup, &ldquo;html.parser&rdquo;)</td>
<td>Python的内置标准库<BR>执行速度适中<BR>文档容错能力强</td>
<td>Python 2.7.3 or 3.2.2前的版本中文档容错能力差</td>
</tr>

<tr>
<td><strong>lxml HTML 解析器</strong></td>
<td>BeautifulSoup(markup, &ldquo;lxml&rdquo;)</td>
<td>速度快<BR>文档容错能力强</td>
<td>需要安装C语言库</td>
</tr>

<tr>
<td><strong>lxml XML 解析器</strong></td>
<td>BeautifulSoup(markup, [&ldquo;lxml-xml&rdquo;])<BR>BeautifulSoup(markup, &ldquo;xml&rdquo;)</td>
<td>速度快<BR>唯一支持XML的解析器</td>
<td>需要安装C语言库</td>
</tr>

<tr>
<td><strong>html5lib</strong></td>
<td>BeautifulSoup(markup, &ldquo;html5lib&rdquo;)</td>
<td>最好的容错性<BR>以浏览器的方式解析文档<BR>生成HTML5格式的文档</td>
<td>速度慢<BR>不依赖外部扩展</td>
</tr>
</tbody>
</table>

<h2 id="1-4-解析示例">1.4 解析示例</h2>

<p><strong>1. 获取标题</strong></p>

<pre><code>print(soup.title)
# &lt;title&gt;Page not found · GitHub Pages&lt;/title&gt;
print(soup.title.name)
# title
print(soup.title.string)
# Page not found · GitHub Pages
print(soup.title.parent.name)
# head
</code></pre>

<p><strong>2. 获取特定标签</strong></p>

<pre><code>print(soup.p)
# 有多个标签时打印第一个
# &lt;p&gt;&lt;strong&gt;File not found&lt;/strong&gt;&lt;/p&gt;

print(soup.h1)
# &lt;h1&gt;404&lt;/h1&gt;

print(soup.div)
print(soup.img)
</code></pre>

<p><strong>3. 获取属性</strong></p>

<pre><code>print(soup.div['class'])
print(soup.div.attrs['class'])
# ['container']

print(soup.div.attrs)
# {'class': ['container']}
</code></pre>

<h1 id="二-解析说明">二、解析说明</h1>

<p><code>Beautiful Soup</code>将复杂<code>HTML</code>文档转换成一个复杂的树形结构,每个节点都是<code>Python</code>对象,所有对象可以归纳为4种: <code>Tag</code> , <code>NavigableString</code>, <code>BeautifulSoup</code>, <code>Comment</code>.</p>

<h2 id="2-1-tag">2.1 Tag</h2>

<p><code>Tag</code>对象与<code>XML</code>或<code>HTML</code>原生文档中的<code>tag</code>相同:</p>

<pre><code>soup = BeautifulSoup('&lt;b class=&quot;boldest&quot;&gt;Extremely bold&lt;/b&gt;')
tag = soup.b
type(tag)
# &lt;class 'bs4.element.Tag'&gt;
</code></pre>

<h3 id="2-1-1-name">2.1.1. Name</h3>

<p>每个<code>tag</code>都有自己的名字,通过<code>.name</code>来获取:</p>

<pre><code>tag.name
# u'b'
</code></pre>

<p>如果改变了tag的name,那将影响所有通过当前Beautiful Soup对象生成的HTML文档:</p>

<pre><code>tag.name = &quot;blockquote&quot;
tag
# &lt;blockquote class=&quot;boldest&quot;&gt;Extremely bold&lt;/blockquote&gt;
</code></pre>

<h3 id="2-1-2-attributes">2.1.2 Attributes</h3>

<p>一个tag可能有很多个属性. tag <code>&lt;b class=&quot;boldest&quot;&gt;</code>有一个 “class” 的属性,值为 “boldest” . tag的属性的操作方法与字典相同:</p>

<pre><code>tag['class']
# u'boldest'
</code></pre>

<p>也可以直接”点”取属性, 比如: .attrs :</p>

<pre><code>tag.attrs
# {u'class': u'boldest'}
</code></pre>

<p><code>tag</code>的属性可以被添加,删除或修改. 再说一次, <code>tag</code>的属性操作方法与字典一样</p>

<pre><code>tag['class'] = 'verybold'
tag['id'] = 1
tag
# &lt;blockquote class=&quot;verybold&quot; id=&quot;1&quot;&gt;Extremely bold&lt;/blockquote&gt;

del tag['class']
del tag['id']
tag
# &lt;blockquote&gt;Extremely bold&lt;/blockquote&gt;

tag['class']
# KeyError: 'class'
print(tag.get('class'))
# None
</code></pre>

<p><strong>1.多值属性</strong></p>

<p><code>HTML4</code>定义了一系列可以包含多个值的属性.在<code>HTML5中</code>移除了一些,却增加更多.最常见的多值的属性是<code>class</code>(一个<code>tag</code>可以有多个CSS的class). 还有一些属性<code>rel</code>, <code>rev</code> , <code>accept-charset</code> , <code>headers</code> , <code>accesskey</code> . 在<code>Beautiful Soup</code>中多值属性的返回类型是<code>list</code>:</p>

<pre><code>css_soup = BeautifulSoup('&lt;p class=&quot;body strikeout&quot;&gt;&lt;/p&gt;')
css_soup.p['class']
# [&quot;body&quot;, &quot;strikeout&quot;]

css_soup = BeautifulSoup('&lt;p class=&quot;body&quot;&gt;&lt;/p&gt;')
css_soup.p['class']
# [&quot;body&quot;]
</code></pre>

<p>如果某个属性看起来好像有多个值,但在任何版本的HTML定义中都没有被定义为多值属性,那么<code>Beautiful Soup</code>会将这个属性作为字符串返回</p>

<pre><code>id_soup = BeautifulSoup('&lt;p id=&quot;my id&quot;&gt;&lt;/p&gt;')
id_soup.p['id']
# 'my id'
</code></pre>

<p>将tag转换成字符串时,多值属性会合并为一个值</p>

<pre><code>rel_soup = BeautifulSoup('&lt;p&gt;Back to the &lt;a rel=&quot;index&quot;&gt;homepage&lt;/a&gt;&lt;/p&gt;')
rel_soup.a['rel']
# ['index']
rel_soup.a['rel'] = ['index', 'contents']
print(rel_soup.p)
# &lt;p&gt;Back to the &lt;a rel=&quot;index contents&quot;&gt;homepage&lt;/a&gt;&lt;/p&gt;
</code></pre>

<p>如果转换的文档是XML格式,那么tag中不包含多值属性</p>

<pre><code>xml_soup = BeautifulSoup('&lt;p class=&quot;body strikeout&quot;&gt;&lt;/p&gt;', 'xml')
xml_soup.p['class']
# u'body strikeout'
</code></pre>

<h2 id="2-2-navigablestring">2.2 NavigableString</h2>

<p>字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:</p>

<pre><code>tag.string
# u'Extremely bold'
type(tag.string)
# &lt;class 'bs4.element.NavigableString'&gt;
</code></pre>

<p>一个<code>NavigableString</code>字符串与<code>Python</code>中的<code>Unicode</code>字符串相同,并且还支持包含在<code>遍历文档树</code>和<code>搜索文档树</code>中的一些特性. 通过<code>unicode()</code>方法可以直接将 <code>NavigableString</code>对象转换成<code>Unicode</code>字符串:</p>

<pre><code>unicode_string = unicode(tag.string)
unicode_string
# u'Extremely bold'
type(unicode_string)
# &lt;type 'unicode'&gt;
</code></pre>

<p><code>tag</code>中包含的字符串不能编辑,但是可以被替换成其它的字符串,用<code>replace_with()</code>方法:</p>

<pre><code>tag.string.replace_with(&quot;No longer bold&quot;)
tag
# &lt;blockquote&gt;No longer bold&lt;/blockquote&gt;
</code></pre>

<p><code>NavigableString</code>对象支持<code>遍历文档树</code>和<code>搜索文档树</code>中定义的大部分属性, 并非全部.尤其是,一个字符串不能包含其它内容(tag能够包含字符串或是其它tag),字符串不支持<code>.contents</code>或<code>.string</code>属性或<code>find()</code>方法.</p>

<p>如果想在<code>Beautiful Soup</code>之外使用<code>NavigableString</code>对象,需要调用<code>unicode()</code>方法,将该对象转换成普通的Unicode字符串,否则就算Beautiful Soup已方法已经执行结束,该对象的输出也会带有对象的引用地址.这样会浪费内存.</p>

<h2 id="2-3-beautifulsoup">2.3 BeautifulSoup</h2>

<p>BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.</p>

<p>因为 BeautifulSoup 对象并不是真正的HTML或XML的tag,所以它没有name和attribute属性.但有时查看它的 .name 属性是很方便的,所以 BeautifulSoup 对象包含了一个值为 “[document]” 的特殊属性 .name</p>

<pre><code>soup.name
# u'[document]'
</code></pre>

<h2 id="2-4-comment">2.4 Comment</h2>

<p>Tag , NavigableString , BeautifulSoup 几乎覆盖了html和xml中的所有内容,但是还有一些特殊对象.容易让人担心的内容是文档的注释部分:</p>

<pre><code>markup = &quot;&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;&quot;
soup = BeautifulSoup(markup)
comment = soup.b.string
type(comment)
# &lt;class 'bs4.element.Comment'&gt;
</code></pre>

<p>Comment 对象是一个特殊类型的 NavigableString 对象:</p>

<pre><code>comment
# u'Hey, buddy. Want to buy a used parser'
</code></pre>

<p>但是当它出现在HTML文档中时, Comment 对象会使用特殊的格式输出:</p>

<pre><code>print(soup.b.prettify())
# &lt;b&gt;
#  &lt;!--Hey, buddy. Want to buy a used parser?--&gt;
# &lt;/b&gt;
</code></pre>

<p><code>Beautiful Soup</code>中定义的其它类型都可能会出现在XML的文档中: CData , ProcessingInstruction , Declaration , Doctype .与 Comment 对象类似,这些类都是 NavigableString 的子类,只是添加了一些额外的方法的字符串独享.下面是用CDATA来替代注释的例子:</p>

<pre><code>from bs4 import CData
cdata = CData(&quot;A CDATA block&quot;)
comment.replace_with(cdata)

print(soup.b.prettify())
# &lt;b&gt;
#  &lt;![CDATA[A CDATA block]]&gt;
# &lt;/b&gt;
</code></pre>

<h1 id="三-查找">三、查找</h1>

<p><code>Beautiful Soup</code>定义了很多搜索方法,这里着重介绍2个: <code>find()</code> 和 <code>find_all()</code> .其它方法的参数和用法类似,请读者举一反三.</p>

<h2 id="3-1-find-all">3.1 find_all()</h2>

<pre><code>find_all(name , attrs , recursive , string , **kwargs )
</code></pre>

<ul>
<li><code>name</code>: 参数可以查找所有名字为<code>name</code>的<code>tag</code></li>
<li><code>attrs</code>:

<ul>
<li><code>id</code>: 查找包含指定<code>id</code>的<code>tag</code></li>
<li><code>href</code>:  <code>href</code>参数, <code>Beautiful Soup</code>会搜索每个<code>tag</code>的<code>href</code>属性:</li>
<li><code>class_</code>: 按照<code>CSS</code>类名搜索tag的功能非常实用,但标识<code>CSS</code>类名的关键字<code>class</code>在Python中是保留字,使用<code>class</code>做参数会导致语法错误.从<code>Beautiful Soup</code>的<code>4.1.1</code>版本开始,可以通过<code>class_</code>参数搜索有指定<code>CSS</code>类名的<code>tag</code>:</li>
<li><code>limit</code>:  limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到<code>limit</code>的限制时,就停止搜索返回结果.如：<code>soup.find_all(&quot;a&quot;, limit=2)</code></li>
</ul></li>
<li><code>recursive</code>: 调用<code>tag</code>的<code>find_all()</code>方法时,<code>Beautiful Soup</code>会检索当前<code>tag</code>的所有子孙节点,如果只想搜索<code>tag</code>的直接子节点,可以使用参数<code>recursive=False</code>.</li>
<li><code>string</code>: 通过<code>string</code>参数可以搜搜文档中的字符串内容<code>.</code>与<code>name</code>参数的可选值一样, <code>string</code> 参数接受 <code>字符串</code> , <code>正则表达式</code> , <code>列表</code>, <code>True</code> . 下面代码用来搜索内容里面包含<code>Elsie</code>的<code>&lt;a&gt;</code>标签:<code>soup.find_all(&quot;a&quot;, string=&quot;Elsie&quot;)</code></li>
</ul>

<p><strong>示例</strong></p>

<pre><code>soup = BeautifulSoup(html_doc, 'html.parser')

# 查找所有的图片标签
print(soup.find_all('img'))

# 查找A标签class=logo
print(soup.find_all('a', &quot;logo&quot;))
print(soup.find_all('a', class_=&quot;logo&quot;))

# 查找DIV下A标签标题为@githubstatus的a标签
print(soup.find_all(&quot;div&quot;, id=&quot;suggestions&quot;, limit=1)[0].find_all('a', string=&quot;@githubstatus&quot;))

# 查找p标签和img标签
print(soup.find_all([&quot;p&quot;, &quot;img&quot;]))
</code></pre>

<h2 id="3-2-find">3.2 find()</h2>

<pre><code>find(name , attrs , recursive , string , **kwargs )
</code></pre>

<p><code>find_all()</code>方法将返回文档中符合条件的所有<code>tag</code>,尽管有时候我们只想得到一个结果.比如文档中只有一个<body>标签,那么使用 <code>find_all()</code>方法来查找<body>标签就不太合适, 使用<code>find_all</code>方法并设置<code>limit=1</code>参数不如直接使用<code>find()</code>方法.下面两行代码是等价的:</p>

<pre><code>soup.find_all('title', limit=1)
# [&lt;title&gt;Page not found · GitHub Pages&lt;/title&gt;]

soup.find('title')
# &lt;title&gt;Page not found · GitHub Pages&lt;/title&gt;
</code></pre>

<p>唯一的区别是<code>find_all()</code>方法的返回结果是值包含一个元素的列表,而<code>find()</code>方法直接返回结果.<code>find_all()</code>方法没有找到目标是返回空列表, <code>find()</code>方法找不到目标时,返回<code>None</code>.</p>

<p><code>soup.head.title</code>是<code>tag</code>的名字方法的简写.这个简写的原理就是多次调用当前<code>tag</code>的<code>find()</code>方法:</p>

<pre><code>soup.head.title
# &lt;title&gt;Page not found · GitHub Pages&lt;/title&gt;

soup.find(&quot;head&quot;).find(&quot;title&quot;)
# &lt;title&gt;Page not found · GitHub Pages&lt;/title&gt;
</code></pre>

<h2 id="3-3-find">3.3 find_{}()</h2>

<ul>
<li>find_parents() 和 find_parent()</li>
<li>find_next_siblings() 和 find_next_sibling()</li>
<li>find_previous_siblings() 和 find_previous_sibling()</li>
<li>find_all_next() 和 find_next()</li>
<li>find_all_previous() 和 find_previous()</li>
</ul>

<h2 id="3-4-css选择器">3.4 CSS选择器</h2>

<p><code>Beautiful Soup</code>支持大部分的<code>CSS</code>选择器 <code>http://www.w3.org/TR/CSS2/selector.html</code>, 在<code>Tag</code>或<code>BeautifulSoup</code>对象的<code>.select()</code>方法中传入字符串参数, 即可使用<code>CSS</code>选择器的语法找到<code>tag</code>:</p>

<pre><code>print(soup.select(&quot;.container&quot;))
print(soup.select(&quot;#suggestions&quot;))
print(soup.select(&quot;div#suggestions&quot;))
</code></pre>

<p>文档地址：<a href="https://beautifulsoup.readthedocs.io/zh_CN/latest/">https://beautifulsoup.readthedocs.io/zh_CN/latest/</a></p>

    <div class="eof">-- EOF --</div>
    <div class="eof_arrow">
        <a href="/"><img src="/static/img/arrow-back.png" style="width:25px;height:25px;" /></a>
    </div>
    
    <div class="eof_tag">
        最后更新于：
        <code style="border:0px;background:none;"><a href="/2017-05.html">2021-09-15 08:27</a></code>
    </div>
    
    <div class="eof_tag">
        发表于：
        <code style="border:0px;background:none;"><a href="/2017-05.html">2017-05-01 19:42</a></code>
    </div>
    <div class="eof_tag">
        标签：
        <code style="border:0px;background:none;"><a href="/tag/python.html">Python</a></code>
        <code style="border:0px;background:none;"><a href="/tag/爬虫.html">爬虫</a></code>
    </div>

    <div id="footer">
        <ul>
            <li>
            <b>上一篇</b>：<a href="/selenium.html">Python爬虫库 ( 4 ) - Selenium</a>
            </li>
            
            <li>
            <b>下一篇</b>：<a href="/scrapy.html">Python爬虫库 ( 6 ) - Scrapy</a>
            </li>
            <li>
                <b>Github地址</b>：<a href="https://github.com/pengbotao/itopic.go/blob/master/posts\python\Python爬虫库 ( 5 ) - BeautifulSoup.md">https://github.com/pengbotao/itopic.go/blob/master/posts\python\Python爬虫库 ( 5 ) - BeautifulSoup.md</a>
            <li>
            <li>
                @2013-2021 老彭的博客&nbsp;[Hosted by <a href="https://pages.github.com/" style="font-weight: bold" target="_blank">Github Pages</a>]
            </li>
        </ul>
    </div>
</div>
<div id="top"><a href="#"><img src="/static/img/arrow-top.png" style="width:40px;height:40px;" /></a></div>

<a href="https://github.com/pengbotao/itopic.go/blob/master/posts\python\Python爬虫库 ( 5 ) - BeautifulSoup.md" target="_blank"  class="github-corner">
<svg width="60" height="60" viewBox="0 0 250 250" style="fill: #61687C; color:#fff; position: absolute;top: 0;border: 0;right: 0;" aria-hidden="true">
    <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
    <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
    <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path>
    </svg>
</a>
</body>
</html>